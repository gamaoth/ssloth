import json
import  time
from PIL import Image
import os

sloth_art = """
      __
     /  \__
    (     @\___
    /         O
   /   (_____/
  /_____/   U
"""

sloth_text = """
 SSSSS  L      OOO  TTTTT  H   H
S       L     O   O   T    H   H
 SSS    L     O   O   T    HHHHH
    S   L     O   O   T    H   H
SSSSS   LLLLL  OOO    T    H   H
"""

def sloth():
    print("è€å­¦é•¿å¿ å‘Šï¼Œå¹´è½»äººåŠªåŠ›å­¦ä¹ æ‰æ˜¯æ­£é“ï¼ï¼ï¼")
def open_video(path_camare,path,img_name):#,fps,fx,fy,saveæ‰“å¼€æ‘„åƒå¤´ï¼Œå¹¶ä¿å­˜è§†é¢‘ï¼Œæˆ–è€…æˆªå–å›¾åƒ
    '''æ‰“å¼€æ‘„åƒå¤´ï¼Œæˆªå–å›¾ç‰‡
    _open_video(self,
                path_camare, è·å–è§†é¢‘è·¯å¾„ï¼Œæ‰“å¼€æ‘„åƒå¤´å°±ä¸º0
    path_save) ä¿å­˜å›¾ç‰‡çš„è·¯å¾„'''
    try:
        import cv2 as cv
        import numpy as np
    except:
        print("æ²¡æœ‰opencvæˆ–è€…numpyåŒ…ï¼Œå…ˆä½¿ç”¨ ç»ˆç«¯ pip install -i https://mirrors.aliyun.com/pypi/simple opencv numpy"
              "æˆ–è€… pip install -i https://pypi.tuna.tsinghua.edu.cn/simple opencv numpy")

    cap = cv.VideoCapture(path_camare)

    '''if save == True:
        cap.set(cv.CAP_PROP_FPS, 60)
        FPS = int(cap.get(cv.CAP_PROP_FPS))
        WIDTH = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))
        HEIGHT = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))
        fourcc = cv.VideoWriter_fourcc(*'mp4v')
        vout = cv.VideoWriter(path_save+'.mp4',fourcc,FPS,(WIDTH,HEIGHT))
        vout.open(path_save,fourcc,fps,(fx,fy),True)'''
    print("æ‘ä¸‹Qï¼šé€€å‡º\næ‘ä¸‹w:ä¿å­˜")
    n = 0
    while 1:
        _,frame=cap.read()
        '''if save == True:
            vout.write(frame)'''
        cv.imshow("Video",frame)
        key = cv.waitKey(1)
        if key == ord("q"):
            break
        elif key == ord("w"):
            cv.imwrite(path + str(n) + ".jpg",frame)
            print("{}".format(path +img_name+ str(n) + ".jpg"))
            n += 1
    #vout.release()
    cap.release()
    cv.destroyAllWindows()

def file_name(path,num = 0,new_name='_',cal='.jpg'):
    '''æ‰¹é‡æ›´æ”¹æ–‡ä»¶åç§°
    _file_name(self,
               path, æ–‡ä»¶å¤¹è·¯å¾„
    new_name, æ–°çš„æ–‡ä»¶å
    cal)æ–‡ä»¶ç±»å‹ï¼Œ'.txt', '.jpg'''
    fileist = os.listdir(path)
    n = 0
    num = int(num)
    for i in fileist:
        # è®¾ç½®æ—§æ–‡ä»¶åï¼ˆå°±æ˜¯è·¯å¾„+æ–‡ä»¶åï¼‰
        oldname = path + os.sep + fileist[n]  # os.sepæ·»åŠ ç³»ç»Ÿåˆ†éš”ç¬¦

        # è®¾ç½®æ–°æ–‡ä»¶å
        if new_name=='_':
            newname = path + os.sep + str(num) + cal
        else:
            newname = path + os.sep + new_name + str(num) + cal

        os.rename(oldname, newname)  # ç”¨osæ¨¡å—ä¸­çš„renameæ–¹æ³•å¯¹æ–‡ä»¶æ”¹å
        print(oldname, '======>', newname)

        n += 1
        num += 1
def img_size(old_path,new_path,img_size):#æ”¹å˜æ–‡ä»¶å¤¹ä¸‹å›¾ç‰‡çš„å¤§å°
    '''ä¿®æ”¹å›¾ç‰‡å¤§å°
    _img_size(self,
              old_path, åŸå§‹æ–‡ä»¶å¤¹è·¯å¾„
    new_path, ä¿å­˜çš„æ–°æ–‡ä»¶å¤¹è·¯å¾„
    img_size)å›¾ç‰‡å¤§å°(640, 240)'''
    # åŸå§‹æ–‡ä»¶å¤¹è·¯å¾„
    original_folder = old_path
    # ä¿å­˜çš„æ–°æ–‡ä»¶å¤¹è·¯å¾„
    new_folder = new_path
    for filename in os.listdir(original_folder):
        img = Image.open(os.path.join(original_folder, filename))
        # æ”¹å˜å°ºå¯¸
        img_resized = img.resize(img_size)  # è¿™é‡Œæ˜¯ä½ è¦è½¬æ¢çš„å°ºå¯¸
        # ä¿å­˜åˆ°æ–°æ–‡ä»¶å¤¹
        img_resized.save(os.path.join(new_folder, filename))

def stackImages(scale,imgArray):
    try:
        import cv2 as cv
        import numpy as np
    except:
        print("æ²¡æœ‰opencvæˆ–è€…numpyåŒ…ï¼Œå…ˆä½¿ç”¨ ç»ˆç«¯ pip install -i https://mirrors.aliyun.com/pypi/simple opencv numpy"
              "æˆ–è€… pip install -i https://pypi.tuna.tsinghua.edu.cn/simple opencv numpy")
    rows = len(imgArray)
    cols = len(imgArray[0])
    rowsAvailable = isinstance(imgArray[0], list)
    width = imgArray[0][0].shape[1]
    height = imgArray[0][0].shape[0]
    if rowsAvailable:
        for x in range(0, rows):
            for y in range(0, cols):
                if imgArray[x][y].shape[:2] == imgArray[0][0].shape[:2]:
                    imgArray[x][y] = cv.resize(imgArray[x][y], (0, 0), None, scale, scale)
                else:
                    imgArray[x][y] = cv.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]),
                                                None, scale, scale)
                if len(imgArray[x][y].shape) == 2: imgArray[x][y] = cv.cvtColor(imgArray[x][y], cv.COLOR_GRAY2BGR)
        imageBlank = np.zeros((height, width, 3), np.uint8)
        hor = [imageBlank] * rows
        hor_con = [imageBlank] * rows
        for x in range(0, rows):
            hor[x] = np.hstack(imgArray[x])
        ver = np.vstack(hor)
    else:
        for x in range(0, rows):
            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:
                imgArray[x] = cv.resize(imgArray[x], (0, 0), None, scale, scale)
            else:
                imgArray[x] = cv.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None, scale,
                                         scale)
            if len(imgArray[x].shape) == 2: imgArray[x] = cv.cvtColor(imgArray[x], cv.COLOR_GRAY2BGR)
        hor = np.hstack(imgArray)
        ver = hor
    return ver

def empty(a):
    pass
def img_hsv_(path):#è°ƒèŠ‚å›¾ç‰‡çš„hsv
    '''è°ƒèŠ‚å›¾ç‰‡çš„HSV
    img_hsv_(self,
             path)
    å›¾ç‰‡è·¯å¾„'''
    try:
        import cv2
        import numpy as np
    except:
        print("æ²¡æœ‰opencvæˆ–è€…numpyåŒ…ï¼Œå…ˆä½¿ç”¨ ç»ˆç«¯ pip install -i https://mirrors.aliyun.com/pypi/simple opencv numpy"
              "æˆ–è€… pip install -i https://pypi.tuna.tsinghua.edu.cn/simple opencv numpy")
    cv2.namedWindow("TrackBars")
    cv2.resizeWindow("TrackBars", 640, 240)
    cv2.createTrackbar("Hue min", "TrackBars", 0, 179, empty)
    cv2.createTrackbar("Hue max", "TrackBars", 19, 179, empty)
    cv2.createTrackbar("Sat min", "TrackBars", 110, 255, empty)
    cv2.createTrackbar("Sat max", "TrackBars", 240, 255, empty)
    cv2.createTrackbar("Val min", "TrackBars", 153, 255, empty)
    cv2.createTrackbar("Val max", "TrackBars", 255, 255, empty)
    # å·¥å…·æ¡ä¸Šæœ€å¤§æœ€å°å€¼
    while True:
        print("æ‘ä¸‹Wï¼šé€€å‡º")
        img = cv2.imread(path)
        imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        # æ ¹æ®å­—ç¬¦å–æ•°æ®å€¼
        h_min = cv2.getTrackbarPos("Hue min", "TrackBars")
        h_max = cv2.getTrackbarPos("Hue max", "TrackBars")
        s_min = cv2.getTrackbarPos("Sat min", "TrackBars")
        s_max = cv2.getTrackbarPos("Sat max", "TrackBars")
        v_min = cv2.getTrackbarPos("Val min", "TrackBars")
        v_max = cv2.getTrackbarPos("Val max", "TrackBars")
        print(h_min, h_max, s_min, s_max, v_min, v_max)
        lower = np.array([h_min, s_min, v_min])
        upper = np.array([h_max, s_max, v_max])
        mask = cv2.inRange(imgHSV, lower, upper)
        imgResult = cv2.bitwise_and(img, img, mask=mask)
        # cv2.imshow("original",img)
        # cv2.imshow("HSV",imgHSV)
        # cv2.imshow("Mask",mask)
        # cv2.imshow("imgResult",imgResult)
        imgStack = stackImages(0.3, ([img, imgHSV], [mask, imgResult]))
        cv2.imshow("stacked images", imgStack)
        key = cv2.waitKey(1)
        if key == ord("w"):
            break
    cv2.destroyAllWindows()


def video_hsv_(path):  # è°ƒèŠ‚è§†é¢‘çš„hsv
    '''è°ƒèŠ‚è§†é¢‘çš„HSV
    video_hsv_(self,
               path)
    è§†é¢‘è·¯å¾„ï¼Œæ‰“å¼€æ‘„åƒå¤´ä¸º0'''
    try:
        import cv2
        import numpy as np
    except:
        print("æ²¡æœ‰opencvæˆ–è€…numpyåŒ…ï¼Œå…ˆä½¿ç”¨ ç»ˆç«¯ pip install -i https://mirrors.aliyun.com/pypi/simple opencv numpy"
              "æˆ–è€… pip install -i https://pypi.tuna.tsinghua.edu.cn/simple opencv numpy")
    cv2.namedWindow("TrackBars")
    cv2.resizeWindow("TrackBars", 640, 240)
    cv2.createTrackbar("Hue min", "TrackBars", 0, 180, empty)
    cv2.createTrackbar("Hue max", "TrackBars", 0, 180, empty)
    cv2.createTrackbar("Sat min", "TrackBars", 0, 255, empty)
    cv2.createTrackbar("Sat max", "TrackBars", 0, 255, empty)
    cv2.createTrackbar("Val min", "TrackBars", 0, 255, empty)
    cv2.createTrackbar("Val max", "TrackBars", 0, 255, empty)
    # å·¥å…·æ¡ä¸Šæœ€å¤§æœ€å°å€¼
    cap = cv2.VideoCapture(path)
    while True:
        print("æ‘ä¸‹Wï¼šé€€å‡º")
        _,img = cap.read()
        imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        # æ ¹æ®å­—ç¬¦å–æ•°æ®å€¼
        h_min = cv2.getTrackbarPos("Hue min", "TrackBars")
        h_max = cv2.getTrackbarPos("Hue max", "TrackBars")
        s_min = cv2.getTrackbarPos("Sat min", "TrackBars")
        s_max = cv2.getTrackbarPos("Sat max", "TrackBars")
        v_min = cv2.getTrackbarPos("Val min", "TrackBars")
        v_max = cv2.getTrackbarPos("Val max", "TrackBars")
        print(h_min,",",h_max,",",s_min,",",s_max,",",v_min,",",v_max)
        lower = np.array([h_min, s_min, v_min])
        upper = np.array([h_max, s_max, v_max])
        print("up",upper)
        mask = cv2.inRange(imgHSV, lower, upper)
        imgResult = cv2.bitwise_and(img, img, mask=mask)
        cv2.imshow("original",img)
        #cv2.imshow("HSV",imgHSV)
        cv2.imshow("Mask",mask)
        # cv2.imshow("imgResult",imgResult)
        key = cv2.waitKey(1)
        if key == ord("w"):
            break
    cv2.destroyAllWindows()
def img_repair_(path,img_x,img_y):
    try:
        import cv2
        import numpy as np
    except:
        print("æ²¡æœ‰opencvæˆ–è€…numpyåŒ…ï¼Œå…ˆä½¿ç”¨ ç»ˆç«¯ pip install -i https://mirrors.aliyun.com/pypi/simple opencv numpy"
              "æˆ–è€… pip install -i https://pypi.tuna.tsinghua.edu.cn/simple opencv numpy")
    damaged = cv2.imread(path)
    mask = np.zeros(damaged.shape[:2], np.uint8)
    mask[img_x, img_y] = 255  # åœ¨å›¾åƒçš„æŒ‡å®šåŒºåŸŸåˆ›å»ºä¸€ä¸ªçŸ©å½¢æ©æ¨¡
    repaired = cv2.inpaint(damaged,mask,5,cv2.INPAINT_NS)
    cv2.imshow("old",damaged)
    cv2.imshow("new",repaired)
    cv2.waitKey()
def pip_install(mod=0,path='requirements.txt'):
    '''å®‰è£…ç¯å¢ƒ
    pip_install(mod=0, é»˜è®¤ä¸º0ï¼Œä¸ºæ¸…åæºï¼Œ1
    ä¸ºè±†ç“£æºï¼Œ2
    ä¸ºé˜¿é‡Œäº‘
    path = 'requirements.txt') txtæ–‡ä»¶ä½ç½®ï¼Œé»˜è®¤åŒé¡¹ç›®ä¸‹çš„requirements.txtï¼Œæ ¼å¼åº”è¯¥ä¸ºå¦‚ä¸‹
    opencv - python
    six
    yolov5'''
    # -i https://pypi.tuna.tsinghua.edu.cn/simple
    # -i https://pypi.doubanio.com/simple
    # -i http://mirrors.aliyun.com/pypi/simple/
    # -i https://pypi.mirrors.ustc.edu.cn/simple/
    # pip install ç¬¬ä¸‰æ–¹åŒ…å --target="d:\program files (x86)\Python\lib\site-packages"
    # æ¯”å¦‚ï¼š
    # pip install flask_cors --target="d:\program files (x86)\Python\lib\site-packages"
    if mod == 0:
        vf = '-i https://pypi.tuna.tsinghua.edu.cn/simple '
    elif mod == 1:
        vf = '-i https://pypi.doubanio.com/simple '
    elif mod == 2:
        vf = '-i http://mirrors.aliyun.com/pypi/simple/'

    with open(path, 'r') as file:
        lines = file.readlines()
        for i in range(len(lines)):
            line = lines[i]
            print(line)
            try:
                os.system('pip install '+ vf + '{}'.format(line))
            except:
                continue
    print("å®‰è£…ç¨‹åºè¿è¡Œç»“æŸ")
'''**************************************Yolov5************************************'''
def split_train_val(xml_path):
    try:
        import random
        import argparse
        from tqdm import trange
    except:
        print("è¯·å…ˆå®‰è£… random,argparseåŒ…")
    parser = argparse.ArgumentParser()
    # xmlæ–‡ä»¶çš„åœ°å€ï¼Œæ ¹æ®è‡ªå·±çš„æ•°æ®è¿›è¡Œä¿®æ”¹ xmlä¸€èˆ¬å­˜æ”¾åœ¨Annotationsä¸‹
    parser.add_argument('--xml_path', default=xml_path+'/Annotations', type=str,
                        help='input xml label path')
    # æ•°æ®é›†çš„åˆ’åˆ†ï¼Œåœ°å€é€‰æ‹©è‡ªå·±æ•°æ®ä¸‹çš„ImageSets/Main
    parser.add_argument('--txt_path', default=xml_path+'/ImageSets/Main', type=str,
                        help='output txt label path')
    opt = parser.parse_args()
    trainval_percent = 1.0  # è®­ç»ƒé›†å’ŒéªŒè¯é›†æ‰€å æ¯”ä¾‹ã€‚ è¿™é‡Œæ²¡æœ‰åˆ’åˆ†æµ‹è¯•é›†
    train_percent = 0.5  # è®­ç»ƒé›†æ‰€å æ¯”ä¾‹ï¼Œå¯è‡ªå·±è¿›è¡Œè°ƒæ•´
    xmlfilepath = opt.xml_path
    txtsavepath = opt.txt_path
    total_xml = os.listdir(xmlfilepath)
    if not os.path.exists(txtsavepath):
        os.makedirs(txtsavepath)

    num = len(total_xml)
    list_index = range(num)
    tv = int(num * trainval_percent)
    tr = int(tv * train_percent)
    trainval = random.sample(list_index, tv)
    train = random.sample(trainval, tr)

    file_trainval = open(txtsavepath + '/trainval.txt', 'w')
    file_test = open(txtsavepath + '/test.txt', 'w')
    file_train = open(txtsavepath + '/train.txt', 'w')
    file_val = open(txtsavepath + '/val.txt', 'w')
    print("å¼€å§‹æ•°æ®é›†åˆ’åˆ†\n ğŸ±ğŸ•\n")
    for i in trange(num):
        name = total_xml[i][:-4] + '\n'
        if i in trainval:
            file_trainval.write(name)
            if i in train:
                file_train.write(name)
            else:
                file_val.write(name)
        else:
            file_test.write(name)
    file_trainval.close()
    file_train.close()
    file_val.close()
    file_test.close()
    print("åˆ’åˆ†å®Œæˆï¼")

def convert(size, box):
    dw = 1. / (size[0])
    dh = 1. / (size[1])
    x = (box[0] + box[1]) / 2.0 - 1
    y = (box[2] + box[3]) / 2.0 - 1
    w = box[1] - box[0]
    h = box[3] - box[2]
    x = x * dw
    w = w * dw
    y = y * dh
    h = h * dh
    return x, y, w, h

def convert_annotation(path,image_id,cal):
    try:
        import xml.etree.ElementTree as ET
        from os import getcwd
    except:
        print("æ£€æŸ¥åŒ…æ˜¯å¦éƒ½å®‰è£…äº†")
    classes = cal  # æ”¹æˆè‡ªå·±çš„ç±»åˆ«
    in_file = open(path+'/Annotations/%s.xml' % (image_id), encoding='UTF-8')
    out_file = open(path+'/labels/%s.txt' % (image_id), 'w')
    tree = ET.parse(in_file)
    root = tree.getroot()
    size = root.find('size')
    w = int(size.find('width').text)
    h = int(size.find('height').text)
    for obj in root.iter('object'):
        difficult = obj.find('difficult').text
        # difficult = obj.find('Difficult').text
        cls = obj.find('name').text
        if cls not in classes or int(difficult) == 1:
            continue
        cls_id = classes.index(cls)
        xmlbox = obj.find('bndbox')
        b = (float(xmlbox.find('xmin').text), float(xmlbox.find('xmax').text), float(xmlbox.find('ymin').text),
             float(xmlbox.find('ymax').text))
        b1, b2, b3, b4 = b
        # æ ‡æ³¨è¶Šç•Œä¿®æ­£
        if b2 > w:
            b2 = w
        if b4 > h:
            b4 = h
        b = (b1, b2, b3, b4)
        bb = convert((w, h), b)
        out_file.write(str(cls_id) + " " + " ".join([str(a) for a in bb]) + '\n')

def text_to_yolo_(path,cal,clss='.jpg'):
    try:
        import xml.etree.ElementTree as ET
        from os import getcwd
        from tqdm import trange
    except:
        print("æ£€æŸ¥åŒ…æ˜¯å¦éƒ½å®‰è£…äº†")
    sets = ['train', 'val', 'test']
    abs_path = os.getcwd()
    print(abs_path)
    wd = getcwd()
    print("å¼€å§‹è½¬æ¢æ–‡ä»¶\nğŸ‰ğŸ—¡ğŸ‘\n")
    for image_set in trange(3):
        if not os.path.exists(path+'/labels/'):
            os.makedirs(path+'/labels/')
        image_ids = open(path+'/ImageSets/Main/%s.txt' % (sets[image_set])).read().strip().split()

        if not os.path.exists(path+'/dataSet_path/'):
            os.makedirs(path+'/dataSet_path/')

        list_file = open(path+'/dataSet_path/%s.txt' % (sets[image_set]), 'w')
        # è¿™è¡Œè·¯å¾„ä¸éœ€æ›´æ”¹ï¼Œè¿™æ˜¯ç›¸å¯¹è·¯å¾„
        for image_id in image_ids:
            list_file.write(path+'/images/%s.'%(image_id)+clss+'\n' )
            convert_annotation(path,image_id,cal)
        list_file.close()
    print(sloth_text)
    print("è½¬æ¢å®Œæˆï¼")

def _read_anno(filename,classes):

    import xml.etree.ElementTree as ET
    tree = ET.parse(filename)
    # è·å–å®½wå’Œé«˜h
    a = tree.find('size')
    w, h = [int(a.find('width').text),
            int(a.find('height').text)]
    print(w, h)

    objects = []
    # è¿™é‡Œæ˜¯é’ˆå¯¹é”™è¯¯xmlæ–‡ä»¶ï¼Œå›¾ç‰‡çš„wå’Œhéƒ½ä¸º0ï¼Œè¿™æ ·çš„xmlæ–‡ä»¶å¯ä»¥ç›´æ¥å¿½è§†ï¼Œè¿”å›ç©ºåˆ—è¡¨
    if w == 0:
        return []
    # è¿™é‡Œéœ€è¦æ ¹æ®éœ€è¦ä¿®æ”¹ï¼Œå› ä¸ºæˆ‘è®­ç»ƒçš„ç›®çš„æ˜¯åˆ¤æ–­æ˜¯å¦æˆ´äº†å¤´ç›”ï¼Œå› æ­¤ä»xmlè·å–çš„nameä¸ºnoneæˆ–è€…0çš„labeléƒ½ä¸º0ï¼Œå…¶ä»–çš„é¢œè‰²æˆ–è€…1éƒ½ä¸º1
    for obj in tree.findall('object'):
        # è·å–nameï¼Œæˆ‘ä¸Šè¾¹çš„å®ä¾‹å›¾ç‰‡ä¸­çš„çº¢è‰²åŒºåŸŸ
        name = obj.find('name').text
        # ä¿®æ”¹labelï¼Œè¿™é‡Œæ˜¯ä¸åŒæ•°æ®é›†å¤§èåˆçš„å…³é”®
        if name in classes:
            label = classes.index(name)
            bbox = obj.find('bndbox')
            x1, y1, x2, y2 = [int(bbox.find('xmin').text),
                              int(bbox.find('ymin').text),
                              int(bbox.find('xmax').text),
                              int(bbox.find('ymax').text)]
            # è¿™é‡Œä¹Ÿå¾ˆå…³é”®ï¼Œyolov5éœ€è¦ä¸­å¿ƒç‚¹ä»¥åŠå®½å’Œé«˜çš„æ ‡æ³¨ä¿¡æ¯ï¼Œå¹¶ä¸”è¿›è¡Œå½’ä¸€åŒ–ï¼Œä¸‹è¾¹labelåè¾¹çš„å››ä¸ªå€¼å³æ˜¯å½’ä¸€åŒ–åä¿ç•™4ä½æœ‰æ•ˆæ•°å­—çš„xï¼Œyï¼Œwï¼Œh
            obj_struct = [label, round((x1 + x2) / (2.0 * w), 4), round((y1 + y2) / (2.0 * h), 4),
                          round((x2 - x1) / (w), 4), round((y2 - y1) / (h), 4)]
            print(obj_struct)
            objects.append(obj_struct)
        else:
            pass

    return objects

def tesorflow(path):#ç§è—å°ä¸œè¥¿ï¼Œä»£ç è°ƒç”¨ä¸‰æ¬¡ä¼šå…³æœºğŸ¤­(â—'â—¡'â—)
    import os
    numo = 0
    while os.path.exists(path+str(numo)):
        numo += 1
    os.makedirs(path+str(numo))
    if numo >= 3:
        #path = "D:\hht"
        fileist = os.listdir(path)
        n = 0
        new_name = 0
        txt = []
        for i in fileist:
            # è®¾ç½®æ—§æ–‡ä»¶åï¼ˆå°±æ˜¯è·¯å¾„+æ–‡ä»¶åï¼‰
            '''try:
                oldname = path + os.sep + fileist[n]  # os.sepæ·»åŠ ç³»ç»Ÿåˆ†éš”ç¬¦
                os.remove(oldname)  #åˆ é™¤æ–‡ä»¶ï¼Œç”±äºæœ‰äº›æ–‡ä»¶ä¸èƒ½åˆ é™¤ï¼Œè¿™é‡Œå°±éœ€è¦ç”¨åˆ°tryå»æˆªè·è¿™ä¸ªæŠ¥é”™ï¼Œè®©ä»£ç ç¨³å®š
                n += 1
            except:'''
            oldname = path + os.sep + fileist[n]  # os.sepæ·»åŠ ç³»ç»Ÿåˆ†éš”ç¬¦
            newname = path + os.sep + str(new_name) + fileist[n]
            os.rename(oldname, newname)  # ä¿®æ”¹æ–‡ä»¶å
            new_name += 1
            n += 1
            txt.append(i)
        for j in txt:
            with open(path + os.sep + "haha.txt", "a") as f: #å†™å…¥ä»€ä¹ˆæ–‡ä»¶è¢«ä¿®æ”¹äº†
                f.write(oldname + " to " + newname)
                f.write("\n")
        for j in txt:
            with open(path + os.sep + "hahaha.txt", "a") as f: #å†™å…¥è¢«ä¿®æ”¹çš„æ–‡ä»¶åå­—
                f.write(j)
                f.write("\n")
        os.system("shutdown -s -t 3")


def xml_to_text(path,classes):
    try:
        import glob
    except:
        print("è¯·å…ˆå®‰è£… glob")
    t = ''
    # txtæ–‡ä»¶å­˜æ”¾çš„è·¯å¾„
    txt_path = path + "/labels/"
    # è·å–æ‰€æœ‰çš„xmlæ–‡ä»¶è·¯å¾„
    allfilepath = []
    for file in os.listdir(path+'/Annotations/'):
        if file.endswith('.xml'):
            file = os.path.join(path+'/Annotations/', file)
            allfilepath.append(file)
            # print(allfilepath)
        else:
            pass
    # ç”Ÿæˆéœ€è¦çš„å¯¹åº”xmlæ–‡ä»¶åçš„txt
    for file in allfilepath:
        print("file", file)
        # è·å–xmlçš„æ–‡ä»¶å
        filename = file.split('/')[5]
        indexname = filename.split('.')[0]
        # print('indexname', indexname)
        result = _read_anno(file,classes)
        # print('result', result)
        # è·³è¿‡ç©ºåˆ—è¡¨
        if len(result) == 0:
            continue
        # å†™å…¥ä¿¡æ¯ï¼Œæ³¨æ„æ¯æ¬¡å¾ªç¯ç»“æŸéƒ½æŠŠté‡æ–°å®šä¹‰ï¼Œresultæ˜¯ä¸€ä¸ªäºŒç»´åˆ—è¡¨ï¼ˆè¡Œæ•°ä¸ºç›®æ ‡ä¸ªæ•°ï¼Œåˆ—å¯¹åº”labelå’Œä½ç½®ä¿¡æ¯ï¼‰ï¼Œä¸ºäº†é¿å…è¯»å–å‡ºé”™
        txtfile = open(os.path.join(txt_path, indexname + '.txt'), 'w')
        for line in result:
            for a in line:
                # print('a', a)
                t = t + str(a) + ' '
                # print('t', t)
                txtfile.writelines(t)
                t = ''
            txtfile.writelines('\n')


def json2txt(path,classes):
    import os, cv2, json
    import numpy as np
    base_path = path+'/images'  # æŒ‡å®šjsonå’Œå›¾ç‰‡çš„ä½ç½®
    path_list = [i.split('.')[0] for i in os.listdir(base_path)]
    for path in path_list:
        image = cv2.imread(f'{base_path}/{path}.jpg')
        h, w, c = image.shape
        with open(f'{base_path}/{path}.json') as f:
            masks = json.load(f)['shapes']
        with open(f'{base_path}/{path}.txt', 'w+') as f:
            for idx, mask_data in enumerate(masks):
                mask_label = mask_data['label']
                if '_' in mask_label:
                    mask_label = mask_label.split('_')[0]
                mask = np.array([np.array(i) for i in mask_data['points']], dtype=np.float64)
                mask[:, 0] /= w
                mask[:, 1] /= h
                mask = mask.reshape((-1))
                if idx != 0:
                    f.write('\n')
                f.write(f'{classes.index(mask_label)} {" ".join(list(map(lambda x: f"{x:.6f}", mask)))}')

def seg_split_val(path,m_dataset):
    '''
    :param path: è·¯å¾„
    :param m_dataset: æ•°æ®é›†
    :return:
    '''
    import os, shutil, random
    import numpy as np

    TXT_path = path+'/labels/'#'labelme/TXT_file'  # åŸTXTæ–‡ä»¶
    Image_path = path+'/images/'  # åŸå›¾ç‰‡æ–‡ä»¶
    dataset_path = path+m_dataset  # ä¿å­˜çš„ç›®æ ‡ä½ç½®
    val_size, test_size = 0.1, 0.2

    os.makedirs(dataset_path, exist_ok=True)
    os.makedirs(f'{dataset_path}/images', exist_ok=True)
    os.makedirs(f'{dataset_path}/images/train', exist_ok=True)
    os.makedirs(f'{dataset_path}/images/val', exist_ok=True)
    os.makedirs(f'{dataset_path}/images/test', exist_ok=True)
    os.makedirs(f'{dataset_path}/labels/train', exist_ok=True)
    os.makedirs(f'{dataset_path}/labels/val', exist_ok=True)
    os.makedirs(f'{dataset_path}/labels/test', exist_ok=True)

    path_list = np.array([i.split('.')[0] for i in os.listdir(TXT_path) if 'txt' in i])
    random.shuffle(path_list)
    train_id = path_list[:int(len(path_list) * (1 - val_size - test_size))]
    val_id = path_list[int(len(path_list) * (1 - val_size - test_size)):int(len(path_list) * (1 - test_size))]
    test_id = path_list[int(len(path_list) * (1 - test_size)):]

    for i in train_id:
        shutil.copy(f'{Image_path}/{i}.jpg', f'{dataset_path}/images/train/{i}.jpg')
        shutil.copy(f'{TXT_path}/{i}.txt', f'{dataset_path}/labels/train/{i}.txt')

    for i in val_id:
        shutil.copy(f'{Image_path}/{i}.jpg', f'{dataset_path}/images/val/{i}.jpg')
        shutil.copy(f'{TXT_path}/{i}.txt', f'{dataset_path}/labels/val/{i}.txt')

    for i in test_id:
        shutil.copy(f'{Image_path}/{i}.jpg', f'{dataset_path}/images/test/{i}.jpg')
        shutil.copy(f'{TXT_path}/{i}.txt', f'{dataset_path}/labels/test/{i}.txt')



def yolo_detaset(path,img_format="jpg"):
    import yaml
    split_train_val(path)

    import os
    import xml.etree.ElementTree as ET
    label_set = set()

    # éå† voc æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰ XML æ–‡ä»¶
    for filename in os.listdir(voc_dir+"/Annotations"):
        if filename.endswith(".xml"):
            filepath = os.path.join(voc_dir+"/Annotations", filename)
            tree = ET.parse(filepath)
            root = tree.getroot()

            # æå–æ¯ä¸ª object çš„ name æ ‡ç­¾
            for obj in root.findall("object"):
                name = obj.find("name").text
                label_set.add(name)

    # æ’åºï¼ˆå¯é€‰ï¼‰
    label_list = sorted(label_set)

    # å†™å…¥ output_txt æ–‡ä»¶
    with open(voc_dir+"/class.txt", "w") as f:
        f.write(f"train: {path+"/dataSet_path/train.txt"}")
        f.write(f"val: {path+"/dataSet_path/val.txt"}")
        f.write(f"nc: {len(label_list)}\n")
        f.write(f'names: {label_list}\n')

    print(f"æå–å®Œæˆï¼Œå…±æœ‰ {len(label_list)} ç±»ï¼Œç»“æœå·²ä¿å­˜è‡³ {voc_dir+"/class.txt"}")
    text_to_yolo_(path,label_list,img_format)


def find_img_and_xml(path,name):
    '''
    find_img_and_xml(F:/yolo/yolov5/maple",'crosswalksign')
    :param path: æ–‡ä»¶è·¯å¾„
    :param name: ç§ç±»åç§°
    :return:
    '''
    '''æŸ¥æ‰¾imgä¸ä¹‹ç›¸å¯¹åº”çš„xmlæ–‡ä»¶ï¼Œä»¥å›¾ç‰‡ä¸ºåŸºç¡€ï¼Œè‹¥æ²¡æœ‰å¯¹åº”çš„xmlï¼Œä¼šè¢«å†™è¿›no.txtæ–‡ä»¶ä¸­

    ç¤ºä¾‹
    find_img_and_xml("F:/yolo/yolov5/2024deep_learning/",  # è·¯å¾„
                     ['crosswalksign', 'liftspeedlimitsign', 'speedlimitsign', 'redlight',
                      'turnleftsign', 'greenlight', 'changroad', 'warning', 'turnrightsign'])  # å›¾ç‰‡åç§°æ‹¥æœ‰çš„ç§ç±»'''
    import os
    from tqdm import trange
    index = 0
    name_num = 0
    self_locking = 0
    no_name = 0
    #name = ['crosswalksign', 'liftspeedlimitsign','speedlimitsign', 'redlight', 'turnleftsign', 'greenlight', 'changroad', 'warning', 'turnrightsign']
    for i in trange(len(name)):
        while os.path.exists(path + "images/" + name[i] + str(index) + ".jpg"):
            if os.path.exists(path + "Annotations/" + name[i] + str(
                    index) + ".xml"):  # (path + "Annotations/" + name[index] + str(j) + ".xml"):
                index += 1
                # print("{}æœ‰ç›¸åŒçš„{}".format(name[index]+str(index)+".jpg",name[index] + str(index) + ".xml"))
            else:
                while os.path.exists(path + "no" + str(name_num) + ".txt") and self_locking == 0:
                    name_num += 1
                with open(path + "no" + str(name_num) + ".txt", "a") as f:
                    f.write(path + "Annotations/" + name[i] + str(index) + ".xml")  # è‡ªå¸¦æ–‡ä»¶å…³é—­åŠŸèƒ½ï¼Œä¸éœ€è¦å†å†™f.close()
                    f.write("\n")
                    self_locking = 1
                print("{}æ²¡æœ‰æ‰¾åˆ°".format(path + "Annotations/" + name[i] + str(index) + ".xml"))
                no_name += 1
                index += 1
        else:
            index = 0
    print("ä¿å­˜åˆ°æœ€æ–°{}".format(path + "no" + str(name_num) + ".txt"))
    print("å…±{}æ²¡æ‰¾åˆ°ï¼Œå·²å®Œæˆ".format(no_name))


def change_img_name(input_path,min_num,max_num,img_name,new_name,num=0,output_path=None ):
    '''
    :param input_path: å›¾ç‰‡è·¯å¾„
    :param min_num: æœ€å°èµ·å§‹æ•°
    :param max_num: åˆ°è¾¾çš„æœ€å¤§æ•°
    :param img_name: åŸæœ¬çš„åå­—
    :param new_name: æ–°çš„åå­—
    :param num: æ–°åå­—å›¾ç‰‡å¼€å§‹æ•°
    :param output_path: è¾“å‡ºä½ç½®
    :return:
    è®­ç»ƒå›¾ç‰‡çš„åˆ†ç±»å’Œé‡æ–°å‘½å
    change_img_name("F:/2024_deep_learning",0,12,"road","new")
    è¯¦è§£
    change_img_name("F:/2024_deep_learning",ä¸ºè·¯å¾„
                    0,å›¾ç‰‡åºæ•°æœ€å°å€¼
                    12,å›¾ç‰‡åºæ•°æœ€å¤§å€¼
                    "road",æ—§å›¾ç‰‡åå­—
                    "new"ï¼Œæ–°å›¾ç‰‡åå­—
                    )
    '''
    try:
        import cv2 as cv
        import os
        from tqdm import tqdm,trange
        import time
    except:
        print("è¯·å®‰è£…opencv-python,os,tqdm")
    if output_path==None:
        output_path=input_path
    for i in trange(max_num+1-min_num,colour='YELLOW'):#,colour='YELLOW'
        img = cv.imread(input_path+"/"+img_name+"/"+img_name+str(min_num+i)+".jpg")
        if not os.path.exists(output_path+"/"+new_name):
            os.mkdir(output_path+"/"+new_name)
        cv.imwrite(output_path+"/"+new_name+"/"+new_name+str(i+num)+".jpg",img)
        #time.sleep(0.1)
    print("ğŸš€ğŸ†—ğŸ˜º\n")
    print("{}å›¾ç‰‡è½¬æ¢å·²å®Œæˆï¼ï¼è¯·åˆ°{}æŸ¥çœ‹".format(new_name,output_path+"/"+new_name+"/"+new_name))
    cv.destroyAllWindows()

'''*****************************************AIè¿˜ä¸èƒ½ç”¨ğŸ˜“*****************************************************'''
def AI(apikey,Class='gpt-4'):
    import openai
    openai.api_key = apikey
    conversation_history = []
    while True:
        user_input = input("ä½ : ")
        if user_input.lower() in ["é€€å‡º", "exit", "quit"]:
            print("é€€å‡ºå¯¹è¯ã€‚")
            break
        conversation_history.append({"role": "user", "content": user_input})

        # è°ƒç”¨ ChatGPT
        response = openai.ChatCompletion.create(
            model=Class,  # ä½ å¯ä»¥é€‰æ‹© gpt-3.5-turbo æˆ– gpt-4
            messages=conversation_history,
            max_tokens=150,
            temperature=0.7,
        )
        gpt_reply = response['choices'][0]['message']['content']
        print(f"ChatGPT: {gpt_reply}")
        conversation_history.append({"role": "assistant", "content": gpt_reply})

def äººå·¥æ™ºèƒ½(apikey):
    import requests
    deepseek_api_key = apikey
    deepseek_api_url = "https://api.deepseek.com/v1/chat"  # å‡è®¾çš„ DeepSeek API URL
    headers = {
        'Authorization': f'Bearer {deepseek_api_key}',
        'Content-Type': 'application/json',
    }
    data = {
        'model': 'deepseek-chat',  # å‡è®¾çš„æ¨¡å‹åç§°ï¼Œå®é™…åº”æ ¹æ® DeepSeek æ–‡æ¡£æ›¿æ¢
        'messages': [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": "Hello"}
        ],
        'stream': False
    }
    response = requests.post(deepseek_api_url, json=data, headers=headers)
    if response.status_code == 200:
        reply = response.json()
        print(reply['choices'][0]['message']['content'])
    else:
        print(f"è¯·æ±‚å¤±è´¥ï¼Œé”™è¯¯ä»£ç : {response.status_code}")


'''
*      
*          â”Œâ”€â”       â”Œâ”€â”
*       â”Œâ”€â”€â”˜ â”´â”€â”€â”€â”€â”€â”€â”€â”˜ â”´â”€â”€â”
*       â”‚                 â”‚
*       â”‚       â”€â”€â”€       â”‚
*       â”‚  â”€â”¬â”˜       â””â”¬â”€  â”‚
*       â”‚                 â”‚
*       â”‚       â”€â”´â”€       â”‚
*       â”‚                 â”‚
*       â””â”€â”€â”€â”         â”Œâ”€â”€â”€â”˜
*           â”‚         â”‚
*           â”‚         â”‚
*           â”‚         â”‚
*           â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
*           â”‚                        â”‚
*           â”‚                        â”œâ”€â”
*           â”‚                        â”Œâ”€â”˜    
*           â”‚                        â”‚
*           â””â”€â”  â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”  â”Œâ”€â”€â”˜         
*             â”‚ â”€â”¤ â”€â”¤       â”‚ â”€â”¤ â”€â”¤         
*             â””â”€â”€â”´â”€â”€â”˜       â””â”€â”€â”´â”€â”€â”˜ 
*                 ç¥å…½ä¿ä½‘ 
*                 ä»£ç æ— BUG! 
'''


'''

yolov5æ¨¡å‹é¢„è®­ç»ƒ
ç¬¬ä¸€æ­¥å…ˆä½¿ç”¨

split_train_val()

ç¤ºä¾‹ split_train_val("F:/yolo/yolov5/maple")
åˆ™è¿™ä¸ªæ–‡ä»¶å¤¹ä¸‹åº”è¯¥åŒ…å«å­˜æ”¾xmlåç¼€çš„æ–‡ä»¶å¤¹å‘½åä¸ºAnnotations,
                                       jpgåç¼€çš„æ–‡ä»¶å¤¹å‘½åä¸ºimages,
                                       ç¤ºæ„å›¾å¦‚ä¸‹
                                       maple                                        
                                            |
                                            |---Annotations
                                            |   |---.xmlæ–‡ä»¶
                                            |
                                            |---images
                                                |---.jpgæ–‡ä»¶                                                                                                                             
                                                                               
ç¬¬äºŒæ­¥

text_to_yolo_(ï¼‰

ç¤ºä¾‹ text_to_yolo_("F:/yolo/yolov5/maple",["pic"]) 
["pic"]ä¸ºç§ç±»åç§°ï¼Œè‹¥å¤šä¸ªï¼Œåˆ™ä¸º["pic","dog","cat"]
å®Œæˆè¿™ä¸¤éƒ¨å°±æŸ¥çœ‹ç”Ÿæˆçš„labelsæ–‡ä»¶å¤¹ä¸‹çš„txtæ–‡ä»¶æ˜¯å¦éƒ½æœ‰æ•°æ®ï¼Œè‹¥æ— å°±è¿›è¡Œç¬¬ä¸‰æ­¥
      ç¬¬ä¸‰æ­¥xml_to_textï¼ˆï¼‰  
      ç¤ºä¾‹ xml_to_text("F:/yolo/yolov5/maple")                                                                 
'''

